{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
        "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "from PIL import Image\n",
        "\n",
        "client = ImageAnalysisClient(\n",
        "    endpoint=\"\",\n",
        "    credential=AzureKeyCredential(\"\")\n",
        ")\n",
        "\n",
        "base_width = 1000\n",
        "img = Image.open('./frames/frame_0000.jpg')\n",
        "\n",
        "wpercent = (base_width / float(img.size[0]))\n",
        "hsize = int((float(img.size[1]) * float(wpercent)))\n",
        "img = img.resize((base_width, hsize), Image.Resampling.LANCZOS)\n",
        "img.save('./frames/frame_0000_.jpg')\n",
        "\n",
        "with open(\"./frames/frame_0000_.jpg\", \"rb\") as f:\n",
        "    image_data = f.read()\n",
        "\n",
        "result = client.analyze(\n",
        "            image_data=image_data,\n",
        "            visual_features=[VisualFeatures.OBJECTS]\n",
        "        )\n",
        "\n",
        "print(\"Image analysis results:\")\n",
        "print(\" Objects:\")\n",
        "\n",
        "if result.objects is not None:\n",
        "    for object in result.objects.list:\n",
        "        print(f\"   '{object.tags[0].name}', {object.bounding_box}, Confidence: {object.tags[0].confidence:.4f}\")\n",
        "\n",
        "print(f\" Image height: {result.metadata.height}\")\n",
        "print(f\" Image width: {result.metadata.width}\")\n",
        "print(f\" Model version: {result.model_version}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1724851867199
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
        "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "\n",
        "client = ImageAnalysisClient(\n",
        "    endpoint=\"\",\n",
        "    credential=AzureKeyCredential(\"\")\n",
        ")\n",
        "\n",
        "# Path to the video file\n",
        "video_path = './Data/test.mp4'\n",
        "# Directory to save frames\n",
        "output_dir = './frames'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "frame_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    success, frame = cap.read()\n",
        "    if not success:\n",
        "        break\n",
        "    else:\n",
        "        frame_path = os.path.join(output_dir, f'frame_{frame_count:04d}.jpg')\n",
        "        cv2.imwrite(frame_path, frame)\n",
        "        frame_count += 1\n",
        "        time.sleep(0.1)\n",
        "cap.release()\n",
        "print(f'{frame_count} frames extracted.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "computervision_client = ComputerVisionClient(\"\", CognitiveServicesCredentials(\"\"))\n",
        "\n",
        "read_image = open(\"./frames/frame_0164.jpg\", \"rb\")\n",
        "\n",
        "# Call API with image and raw response (allows you to get the operation location)\n",
        "read_response = computervision_client.read_in_stream(read_image, raw=True)\n",
        "# Get the operation location (URL with ID as last appendage)\n",
        "read_operation_location = read_response.headers[\"Operation-Location\"]\n",
        "# Take the ID off and use to get results\n",
        "operation_id = read_operation_location.split(\"/\")[-1]\n",
        "\n",
        "# Call the \"GET\" API and wait for the retrieval of the results\n",
        "while True:\n",
        "    read_result = computervision_client.get_read_result(operation_id)\n",
        "    if read_result.status.lower () not in ['notstarted', 'running']:\n",
        "        break\n",
        "    print ('Waiting for result...')\n",
        "    time.sleep(10)\n",
        "\n",
        "# Print results, line by line\n",
        "if read_result.status == OperationStatusCodes.succeeded:\n",
        "    for text_result in read_result.analyze_result.read_results:\n",
        "        for line in text_result.lines:\n",
        "            print(line.text)\n",
        "            print(line.bounding_box)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "import re\n",
        "import time\n",
        "\n",
        "read_image_url = \"https://img.pistonheads.com/LargeSize/ford/focus-st/st-3/ford-focus-st-st-3-S4788196-1.jpg\"\n",
        "computervision_client = ComputerVisionClient(\"\", CognitiveServicesCredentials(\"\"))\n",
        "\n",
        "# Regular expression for UK VRN\n",
        "vrn_pattern = r'^[A-Z]{2}[0-9]{2}\\s?[A-Z]{3}$|^[A-Z]{1,2}[0-9]{1,4}\\s?[A-Z]{1,3}$|^[A-Z]{3}\\s?[0-9]{1,4}$'\n",
        "\n",
        "# Call API with URL and raw response (allows you to get the operation location)\n",
        "read_response = computervision_client.read(read_image_url,  raw=True)\n",
        "\n",
        "# Get the operation location (URL with an ID at the end) from the response\n",
        "read_operation_location = read_response.headers[\"Operation-Location\"]\n",
        "\n",
        "# Grab the ID from the URL\n",
        "operation_id = read_operation_location.split(\"/\")[-1]\n",
        "\n",
        "# Call the \"GET\" API and wait for it to retrieve the results \n",
        "while True:\n",
        "    read_result = computervision_client.get_read_result(operation_id)\n",
        "    if read_result.status not in ['notStarted', 'running']:\n",
        "        break\n",
        "    time.sleep(1)\n",
        "\n",
        "# Print the detected text, line by line\n",
        "if read_result.status == OperationStatusCodes.succeeded:\n",
        "    for text_result in read_result.analyze_result.read_results:\n",
        "        for line in text_result.lines:\n",
        "            if re.match(vrn_pattern, line.text):\n",
        "                print(line.text)\n",
        "                print(line.bounding_box)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Coordinates of the bounding box\n",
        "points = np.array([[510, 1111], [791, 1113], [790, 1183], [510, 1180]], np.int32)\n",
        "points = points.reshape((-1, 1, 2))\n",
        "\n",
        "# Load your image\n",
        "image = cv2.imread('path_to_your_image.jpg')\n",
        "\n",
        "# Draw the bounding box\n",
        "cv2.polylines(image, [points], isClosed=True, color=(0, 255, 0), thickness=2)\n",
        "\n",
        "# Save or display the image\n",
        "cv2.imwrite('output_image.jpg', image)\n",
        "cv2.imshow('Image with Bounding Box', image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "azureml_py310_sdkv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
